{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d40e58e-efc2-4947-b808-455c3a239acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn import preprocessing\n",
    "from obspy.signal.headers import clibsignal\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import obspy as op\n",
    "from obspy import read,read_inventory,read_events, UTCDateTime, Stream, Trace\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.signal.rotate import rotate_ne_rt\n",
    "from obspy.geodetics import gps2dist_azimuth,kilometers2degrees\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adcd26-b9a9-45b2-ac84-3b7fa5358563",
   "metadata": {},
   "source": [
    "____________\n",
    "# Setup\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e400d2-d641-4abb-8f26-6ec9b323bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========\n",
    "# DIRECTORIES\n",
    "# ===========\n",
    "\n",
    "## ------------------------\n",
    "## Directory with waveforms (SeisComP Data Structure)\n",
    "## The basic directory and file layout is defined as:\n",
    "## <SDSdir>/Year/NET/STA/CHAN.TYPE/NET.STA.LOC.CHAN.TYPE.YEAR.DAY\n",
    "\n",
    "#WAVEFORM_DIR = ['/medata01/SEISCOMP_DATA/','/medata02/SEISCOMP_DATA/','/medata03/SEISCOMP_DATA/']\n",
    "WAVEFORM_DIR = ['/media/sysop/14f7ead0-5dcb-4557-a139-55dbb404d11a/diogoloc/dados_posdoc/RSBR_15_years/obspyDMT/mvco/']\n",
    "\n",
    "## ---------------------------\n",
    "## Directory with the catalog (.CSV file of the National Earthquake Information Center (NEIC))\n",
    "## The file layout is defined as:\n",
    "## time,latitude,longitude,depth,mag,magType,nst,gap,dmin,rms,net,id,updated,place,type,horizontalError,depthError,magError,magNst,status,locationSource,magSource\n",
    "\n",
    "CATALOG_FILE = '/home/sysop/dados_posdoc/RSBR_15_years/obspyDMT/CATALOG/CMTSOLUTIONS_2010_2025.xml'\n",
    "\n",
    "## ----------------------------\n",
    "## Directory of the StationXML:\n",
    "\n",
    "XML_DIR = '/home/sysop/dados_posdoc/RSBR_15_years/obspyDMT/mvco/XML/'\n",
    "\n",
    "## -----------------------\n",
    "## Directory of the output (Figures and Feathers file)\n",
    "\n",
    "ORIENTATION_OUTPUT = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/OUTPUT/'\n",
    "\n",
    "# ==========\n",
    "# PARAMETERS\n",
    "# ==========\n",
    "\n",
    "## -------------------------------------------------------------------\n",
    "## Apply band-pass filtering to the seismograms using the range above:\n",
    "\n",
    "PERIOD_BANDS = [0.02,0.5]\n",
    "\n",
    "## ===================================================================================\n",
    "## Default parameters to define the signal and noise windows used to estimate the SNR:\n",
    "\n",
    "## ------------------------------------------------------------------------------\n",
    "## Duration of the signal window before and after the P-wave arrival (in seconds)\n",
    "\n",
    "TIME_WINDOW = 120\n",
    "\n",
    "## ---------------------------------------------------------------\n",
    "## P-wave time window for events (in seconds after P-wave arrival)\n",
    "\n",
    "TIME_FINAL_P = 5\n",
    "\n",
    "## ---------------------------------------------\n",
    "## Minimum earthquake magnitude to be considered\n",
    "\n",
    "minmagnitude = 6\n",
    "\n",
    "## ---------------\n",
    "## MULTIPROCESSING\n",
    "\n",
    "num_processes = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8131ee-42db-44ad-aedf-c11a8e44fe5d",
   "metadata": {},
   "source": [
    "---\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48373d9-8612-453e-8541-b524a99126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quakeml_to_dataframe(quakeml_file):\n",
    "    # Read the QuakeML file using ObsPy\n",
    "    catalog = read_events(quakeml_file)\n",
    "    \n",
    "    entries = []\n",
    "    \n",
    "    for event in catalog:\n",
    "        # Extract basic event information\n",
    "        origin = event.preferred_origin() or event.origins[0]\n",
    "        magnitude = event.preferred_magnitude() or event.magnitudes[0]\n",
    "        \n",
    "        # Extract moment tensor (if available)\n",
    "        moment_tensor = [0, 0, 0, 0, 0, 0]  # Default if no tensor exists\n",
    "        \n",
    "        if event.focal_mechanisms:\n",
    "            fm = event.focal_mechanisms[0]\n",
    "            if fm.moment_tensor:\n",
    "                mt = fm.moment_tensor.tensor\n",
    "                moment_tensor = [\n",
    "                    mt.m_rr,\n",
    "                    mt.m_tt,\n",
    "                    -mt.m_pp,  # Mff = -Mpp\n",
    "                    mt.m_rt,\n",
    "                    -mt.m_rp,  # Mrf = -Mrp\n",
    "                    -mt.m_tp   # Mtf = -Mtp\n",
    "                ]\n",
    "\n",
    "        # Append event data to entries list\n",
    "        entries.append({\n",
    "            'time': origin.time.datetime,\n",
    "            'latitude': origin.latitude,\n",
    "            'longitude': origin.longitude,\n",
    "            'depth': origin.depth / 1000,  # Convert from m to km\n",
    "            'mag': magnitude.mag,\n",
    "            'magType': magnitude.magnitude_type,\n",
    "            'moment tensor': moment_tensor\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(entries)\n",
    "    return df\n",
    "\n",
    "\n",
    "def moment_tensor_to_nodal_planes(input_mt):\n",
    "\n",
    "    mrr, mtt, mff, mrt, mrf, mtf = input_mt \n",
    "    \n",
    "    \"\"\"\n",
    "    Function Name: moment\n",
    "    Description: Computes scalar seismic moment, compensated linear vector dipole (CLVD) ratio, deviatoric components, isotropic component and its ratio, eigenvectors, and position on the Hudson diagram.\n",
    "   \n",
    "    Extracted from: https://github.com/Jose-Alvarez/FMC/blob/master/FMC.py\n",
    "    Original Author: Jose A. Alvarez-Gomez\n",
    "    Year: 2015\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construct the seismic moment tensor (M)\n",
    "    M = np.array([\n",
    "        [mrr, mrt, mrf],\n",
    "        [mrt, mtt, mtf],\n",
    "        [mrf, mtf, mff]\n",
    "    ])\n",
    "\n",
    "    # Remove the isotropic part (mean trace)\n",
    "    trace = np.trace(M) / 3.0\n",
    "    M_dev = M - np.eye(3) * trace  # Deviatoric moment tensor\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(M_dev)\n",
    "\n",
    "    # Sort eigenvalues in ascending order (λ1 < λ2 < λ3)\n",
    "    idx = np.argsort(eigvals)\n",
    "    lambda1, lambda2, lambda3 = eigvals[idx]\n",
    "    v1, v2, v3 = eigvecs[:, idx[0]], eigvecs[:, idx[1]], eigvecs[:, idx[2]]\n",
    "\n",
    "    # Define principal axes\n",
    "    P_axis = v1  # Maximum compression (smallest eigenvalue)\n",
    "    B_axis = v2  # Neutral axis (intermediate eigenvalue)\n",
    "    T_axis = v3  # Maximum tension (largest eigenvalue)\n",
    "\n",
    "    # Compute plunges of principal axes   \n",
    "    plungP = calculate_plunge(P_axis)  # Plunge of P-axis\n",
    "    plungB = calculate_plunge(B_axis)  # Plunge of B-axis\n",
    "    plungT = calculate_plunge(T_axis)  # Plunge of T-axis\n",
    "\n",
    "    # Return plunges\n",
    "    return (plungP, plungB, plungT)\n",
    "       \n",
    "def calculate_plunge(v):\n",
    "    \"\"\"Returns the plunge of vector v in degrees\"\"\"\n",
    "    return math.degrees(math.asin(abs(v[2])))\n",
    "\n",
    "def mecclass(plunges):\n",
    "    \"\"\"\n",
    "    Function Name: mecclass\n",
    "    Description: Classifies the rupture type of an earthquake based on the plunges of the P, B, and T axes.\n",
    "    \n",
    "    Extracted from: https://github.com/Jose-Alvarez/FMC/blob/master/FMC.py\n",
    "    Original Author: Jose A. Alvarez-Gomez\n",
    "    Year: 2015\n",
    "    \"\"\"\n",
    "\n",
    "    plunges = np.asarray(plunges)\n",
    "\n",
    "    P = plunges[0]\n",
    "    B = plunges[1]\n",
    "    T = plunges[2]\n",
    "\n",
    "    maxplung, axis = plunges.max(0), plunges.argmax(0)\n",
    "    \n",
    "    if maxplung >= 67.5:\n",
    "        if axis == 0:  # P max\n",
    "            clase = 'N'  # normal faulting\n",
    "        elif axis == 1:  # B max\n",
    "            clase = 'SS'  # strike-slip faulting\n",
    "        elif axis == 2:  # T max\n",
    "            clase = 'R'  # reverse faulting\n",
    "    else:\n",
    "        if axis == 0:  # P max\n",
    "            if B > T:\n",
    "                clase = 'N-SS'  # normal - strike-slip faulting\n",
    "            else:\n",
    "                clase = 'N'  # normal faulting\n",
    "        if axis == 1:  # B max\n",
    "            if P > T:\n",
    "                clase = 'SS-N'  # strike-slip - normal faulting\n",
    "            else:\n",
    "                clase = 'SS-R'  # strike-slip - reverse faulting\n",
    "        if axis == 2:  # T max\n",
    "            if B > P:\n",
    "                clase = 'R-SS'  # reverse - strike-slip faulting\n",
    "            else:\n",
    "                clase = 'R'  # reverse faulting\n",
    "    return clase\n",
    "\n",
    "def adjust_baz_for_ZEN(baz_original):\n",
    "    \"\"\"\n",
    "    Ajusta o BAZ (Back-Azimute) para o sistema ZEN (troca de N e E).\n",
    "    \n",
    "    Parâmetros:\n",
    "    -----------\n",
    "    baz_original : float\n",
    "        Back-azimute no sistema ZNE (em graus, 0° a 360°).\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    float\n",
    "        Novo BAZ no sistema ZEN (em graus, 0° a 360°).\n",
    "    \"\"\"\n",
    "    baz_ZEN = baz_original - 90\n",
    "    # Ajusta para o intervalo [0°, 360°)\n",
    "    baz_ZEN = baz_ZEN % 360\n",
    "    return baz_ZEN\n",
    "\n",
    "def rms(x):\n",
    "    \"\"\"\n",
    "    Function to calculate root-mean-square of array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :class:`~numpy.ndarray`\n",
    "        Input array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rms : float\n",
    "        Root-Mean-Square value of `x`\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "def energy(x):\n",
    "    \"\"\"\n",
    "    Function to calculate energy of array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :class:`~numpy.ndarray`\n",
    "        Input array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    energy : float\n",
    "        Square value of `x`\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sum(x**2)\n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def aic_simple(a):\n",
    "    r\"\"\"\n",
    "    Simple Akaike Information Criterion [Maeda1985]_.\n",
    "\n",
    "    It's computed directly from input data :math:`a` and defined as\n",
    "\n",
    "    .. math::\n",
    "        \\text{AIC}(k) = k\\log(\\text{Var}(a_{1..k})) +\n",
    "                        (N-k-1)\\log(\\text{Var}(a_{k+1..N}))\n",
    "\n",
    "    which variance denoted as :math:`\\text{Var}`.\n",
    "\n",
    "    The true output is one data sample less. To make it convenient with other\n",
    "    metrics in this module, where the output length is preserved, the last\n",
    "    element is appended to the output: ``aic[-2] == aic[-1]``.\n",
    "\n",
    "    :type a: :class:`numpy.ndarray` or :class:`list`\n",
    "    :param a: Input time series\n",
    "    :rtype: :class:`numpy.ndarray`\n",
    "    :return: aic - Akaike Information Criterion array\n",
    "\n",
    "    Extracted from: https://docs.obspy.org/_modules/obspy/signal/trigger.html#aic_simple\n",
    "\n",
    "    \"\"\"\n",
    "    n = len(a)\n",
    "    if n <= 2:\n",
    "        return np.zeros(n, dtype=np.float64)\n",
    "    a = np.ascontiguousarray(a, np.float64)\n",
    "    aic_res = np.empty(n, dtype=np.float64)\n",
    "    clibsignal.aic_simple(aic_res, a, n)\n",
    "    return aic_res\n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def find_orientation(baz,SS,SZR,ERTR,ERRZ):\n",
    "\n",
    "    \"\"\"\n",
    "    This function calculates the best back azimuth (phi) and sensor misorientation (theta) based on the \n",
    "    given quality criteria: signal strength (SS), similarity of vertical and radial components (SZR), \n",
    "    transverse-to-radial energy ratio (ERTR), and radial-to-vertical energy ratio (ERRZ).\n",
    "\n",
    "    The cost function combines these criteria in such a way that minimazing the cost function helps to\n",
    "    find the optimal back azimuth and corresponding orientation. The function outputs the best back azimuth, orientation,\n",
    "    and the values of the quality criteria at the best azimuth index.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    baz : float\n",
    "        Initial back azimuth value from the taup model (degrees).\n",
    "    SS : np.array\n",
    "        Array of signal strength values for each azimuth angle.\n",
    "    SZR : np.array\n",
    "        Array of similarity values between vertical and radial components for each azimuth angle.\n",
    "    ERTR : np.array\n",
    "        Array of transverse-to-radial energy ratios for each azimuth angle.\n",
    "    ERRZ : np.array\n",
    "        Array of radial-to-vertical energy ratios for each azimuth angle.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    phi : float\n",
    "        The best back azimuth angle (degrees) that minimizes the cost function.\n",
    "    theta : float\n",
    "        The sensor misorientation angle (degrees), defined as the difference between the true back azimuth \n",
    "        and the estimated back azimuth.\n",
    "    SS_best : float\n",
    "        The signal strength value at the best azimuth.\n",
    "    SZR_best : float\n",
    "        The similarity between vertical and radial components at the best azimuth.\n",
    "    ERTR_best : float\n",
    "        The transverse-to-radial energy ratio at the best azimuth.\n",
    "    ERRZ_best : float\n",
    "        The radial-to-vertical energy ratio at the best azimuth.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find best index\n",
    "    cost_function = (\n",
    "                SS -  # Minimizing energy\n",
    "                SZR ) # Maximizing similarity\n",
    "    \n",
    "    # Best index will minimize the cost function                    \n",
    "    best_index = np.argmin(cost_function)\n",
    "    \n",
    "    # --------------------\n",
    "    # Search Space of BAZ\n",
    "\n",
    "    # Step size for the azimuth search (in degrees).\n",
    "    dphi = 0.1\n",
    "\n",
    "    # Array of azimuth angles to search through (in degrees).\n",
    "    ang = np.arange(0., 360., dphi)\n",
    "                            \n",
    "    # Get azimuth and correct for angles above 360\n",
    "    phi = round(ang[best_index])\n",
    "    theta = round(baz - ang[best_index])\n",
    "\n",
    "    # Expressed as a deviation from North\n",
    "    theta = theta % 360          # Convert to (0°, 360°)\n",
    "    if theta > 180:              \n",
    "        theta -= 360             # Convert to (-180°, 180°)\n",
    "                            \n",
    "    # Get argument of maximum coherence:\n",
    "    SS_best = SS[best_index]\n",
    "    SZR_best = SZR[best_index]\n",
    "    ERTR_best = ERTR[best_index]\n",
    "    ERRZ_best = ERRZ[best_index]\n",
    "\n",
    "    return phi,theta,SS_best,SZR_best,ERTR_best,ERRZ_best\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def Braunmiller_Pornsopin_algorithm(tr1,tr2,trZ,noise,baz,time_ins,CCVR_MIN=0.5,SNR_MIN=10,TRR_MIN=0.2,RVR_MIN=2):\n",
    "\n",
    "    \"\"\"\n",
    "    Estimate back azimuth using P-wave particle motion and apply quality criteria.\n",
    "\n",
    "    This algorithm estimates the back azimuth by analyzing P-wave particle motion in an isotropic, \n",
    "    homogeneous layered medium. In such a medium, the P-wave energy propagates along a great circle \n",
    "    path between the source and receiver, with horizontal components defining the radial direction.\n",
    "    The angle between the radial direction and true north gives the back azimuth. The P-wave energy \n",
    "    is confined to the vertical and radial components, with no energy in the transverse component.\n",
    "\n",
    "    The sensor 'misorientation angle' is the difference between the true back azimuth (from the taup model) \n",
    "    and the empirically estimated back azimuth, with positive values representing a clockwise misorientation.\n",
    "\n",
    "    This method applies several quality criteria to filter out unreliable results from component malfunctions or \n",
    "    missing horizontal components:\n",
    "    \n",
    "    == Quality criteria for automatic processing ==\n",
    "\n",
    "    To select reliable back azimuths in automatic processing, the following five quality criteria are applied:\n",
    "     - (1) Overall signal strength of the radial component.\n",
    "     - (2) Similarity between the vertical and radial components.\n",
    "     - (3) Transverse-to-radial energy ratio.\n",
    "     - (4) Radial-to-vertical energy ratio.\n",
    "     - (5) Signal-to-noise ratio (SNR) on the vertical component.\n",
    "\n",
    "    The function uses these criteria to assess the quality of the estimated back azimuth, and classifies the result \n",
    "    as 'good' or 'bad' based on the user-defined thresholds.\n",
    "\n",
    "    -----------  \n",
    "    Parameters:\n",
    "    ----------\n",
    "    tr1 : np.array\n",
    "        The first horizontal component of the seismogram.\n",
    "    tr2 : np.array\n",
    "        The second horizontal component of the seismogram.\n",
    "    trZ : np.array\n",
    "        The vertical component of the seismogram.\n",
    "    noise : np.array\n",
    "        Noise window to calculate the signal-to-noise ratio (SNR).\n",
    "    baz : float\n",
    "        Back azimuth from the taup model (in degrees).\n",
    "    time_ins : float\n",
    "        Difference between observed and predicted travel time\n",
    "        using available data of distant earthquake (in seconds).\n",
    "    CCVR_MIN : float, optional\n",
    "        Minimum required similarity of vertical and radial components (default is 0.45).\n",
    "    SNR_MIN : float, optional\n",
    "        Minimum required signal-to-noise ratio (default is 10).\n",
    "    TRR_MIN : float, optional\n",
    "        Minimum required transverse-to-radial energy ratio (default is 0.45).\n",
    "    RVR_MIN : float, optional\n",
    "        Minimum allowed radial-to-vertical energy ratio (default is -1).\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the following calculated quality criteria, estimated azimuth, and additional results:\n",
    "        \n",
    "        - 'phi' : float\n",
    "            The estimated back azimuth angle (in degrees) based on the best-fit azimuth search.\n",
    "        \n",
    "        - 'baz' : float\n",
    "            The true back azimuth (in degrees) from the taup model, which serves as a reference for comparison with the estimated azimuth.\n",
    "        \n",
    "        - 'SNR' : float\n",
    "            The signal-to-noise ratio (SNR) of the vertical component, expressed in decibels (dB), representing the strength of the signal relative to noise.\n",
    "        \n",
    "        - 'quality' : str\n",
    "            A classification of the estimated azimuth quality ('good' or 'bad'), based on the comparison of various quality criteria and thresholds.\n",
    "        \n",
    "        - 'theta' : float\n",
    "            The sensor misorientation angle (in degrees), representing the difference between the true back azimuth (from the taup model) and the empirically estimated azimuth.\n",
    "        \n",
    "        - 'SS_best' : float\n",
    "            The best signal strength value for the optimal azimuth, quantifying the energy of the radial component for the best-fit azimuth.\n",
    "        \n",
    "        - 'SZR_best' : float\n",
    "            The best similarity score between the vertical and radial components for the optimal azimuth, indicating how well the vertical and radial components align.\n",
    "        \n",
    "        - 'ERTR_best' : float\n",
    "            The best transverse-to-radial energy ratio for the optimal azimuth, assessing the degree to which the transverse component contaminates the radial component.\n",
    "        \n",
    "        - 'ERRZ_best' : float\n",
    "            The best radial-to-vertical energy ratio for the optimal azimuth, showing the relative strength of the radial component compared to the vertical component.\n",
    "        \n",
    "        - 'signal_strength' : np.array\n",
    "            A NumPy array containing the signal strength values for each azimuth tested in the search range, reflecting the overall energy of the radial component.\n",
    "        \n",
    "        - 'similarity_ZR' : np.array\n",
    "            A NumPy array containing the similarity (correlation) coefficients between the vertical and radial components for each azimuth tested.\n",
    "        \n",
    "        - 'energy_ratio_TR' : np.array\n",
    "            A NumPy array containing the transverse-to-radial energy ratios for each azimuth tested, evaluating the amount of transverse energy relative to radial energy.\n",
    "        \n",
    "        - 'max_value_HHR_N' : float\n",
    "            The gain (amplification factor) of radial maximum amplitude of the North-South (HHN) component.\n",
    "        \n",
    "        - 'max_value_HHR_E' : float\n",
    "            The gain (amplification factor) of radial maximum amplitude of the East-West (HHE) component.\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    The algorithm assumes that the back azimuth is between 0 and 360 degrees and that the sensor \n",
    "    misorientation is defined as the difference between the true back azimuth and the empirically estimated back azimuth.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --------------------\n",
    "    # Search Space of BAZ\n",
    "\n",
    "    # Step size for the azimuth search (in degrees).\n",
    "    dphi = 0.1\n",
    "\n",
    "    # Array of azimuth angles to search through (in degrees).\n",
    "    ang = np.arange(0., 360., dphi)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Initialize quality criteria\n",
    "    \n",
    "    signal_strength = np.zeros(len(ang))\n",
    "    similarity_ZR = np.zeros(len(ang))\n",
    "    energy_ratio_TR = np.zeros(len(ang))\n",
    "    energy_ratio_RZ = np.zeros(len(ang))\n",
    "  \n",
    "    # Search through azimuths and find best-fit azimuth\n",
    "    for k, an in enumerate(ang):\n",
    "        R, T = rotate_ne_rt(tr1, tr2, an)\n",
    "\n",
    "        # (1) Overall signal strength of the transversal component\n",
    "        signal_strength[k] = energy(T)\n",
    "\n",
    "        # (2) Similarity of vertical and radial components\n",
    "        similarity_ZR[k] = np.corrcoef(trZ, R)[0, 1]\n",
    "        \n",
    "        # (3) Transverse-to-radial energy ratio\n",
    "        energy_ratio_TR[k] = energy(T) / energy(R)\n",
    "        \n",
    "        # (4) Radial-to-vertical energy ratio\n",
    "        energy_ratio_RZ[k] = energy(R) / energy(trZ)  \n",
    "    \n",
    "    # (5) Signal-to-noise ratio on vertical component\n",
    "    SNR = round(10.0 * np.log10(rms(trZ)**2 / rms(noise)**2), 1)\n",
    "\n",
    "    # Normalizing the signal strength of the transversal component\n",
    "    signal_strength = (signal_strength - np.min(signal_strength)) / (np.max(signal_strength) - np.min(signal_strength)) \n",
    "\n",
    "    phi,theta,SS_best,SZR_best,ERTR_best,ERRZ_best = find_orientation(baz,signal_strength,similarity_ZR,energy_ratio_TR,energy_ratio_RZ)\n",
    "\n",
    "    # Estimating: instrument gain HHN\n",
    "    new_R_N, new_T_N = rotate_ne_rt(tr1, tr2, phi)\n",
    "\n",
    "    max_value_HHR_N = np.max(abs(new_R_N))\n",
    "    \n",
    "    # Estimating: instrument gain HHE\n",
    "    new_R_E, new_T_E = rotate_ne_rt(tr2, tr1, adjust_baz_for_ZEN(phi))\n",
    "\n",
    "    max_value_HHR_E = np.max(abs(new_R_E))\n",
    "\n",
    "    # Estimating: instrument gain HHZ\n",
    "    \n",
    "    max_value_HHZ = np.max(abs(trZ))\n",
    "\n",
    "\n",
    "    if (SZR_best >= CCVR_MIN) & (SNR >= SNR_MIN) & (ERTR_best < TRR_MIN) & (ERRZ_best >= RVR_MIN) &  (-90 < time_ins < 90):\n",
    "        quality = 'good'\n",
    "    else:\n",
    "        quality = 'bad'\n",
    "\n",
    "    # Collect results\n",
    "    results = {\n",
    "        'phi': phi,\n",
    "        'baz': baz,\n",
    "        'SNR': SNR,\n",
    "        'quality': quality,\n",
    "        'theta': theta,\n",
    "        'SS_best': SS_best,\n",
    "        'SZR_best': SZR_best,\n",
    "        'ERTR_best': ERTR_best,\n",
    "        'ERRZ_best': ERRZ_best,\n",
    "        'signal_strength': signal_strength,\n",
    "        'similarity_ZR': similarity_ZR,\n",
    "        'energy_ratio_TR': energy_ratio_TR,\n",
    "        'energy_ratio_RZ': energy_ratio_RZ,\n",
    "        'gain_HHN': max_value_HHR_N,\n",
    "        'gain_HHE': max_value_HHR_E,        \n",
    "        'gain_HHZ': max_value_HHZ,        \n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48e567-c721-45f0-ae93-c26b63ecec53",
   "metadata": {},
   "source": [
    "---\n",
    "# Main program\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5816da9d-0a59-47f2-913b-920bfea570e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Reading catalog\n",
      "===============\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/CATALOG/CMTSOLUTIONS_2010_2025.xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m===============\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m cat \u001b[38;5;241m=\u001b[39m quakeml_to_dataframe(CATALOG_FILE)\n\u001b[1;32m      7\u001b[0m cat\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mquakeml_to_dataframe\u001b[0;34m(quakeml_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquakeml_to_dataframe\u001b[39m(quakeml_file):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Read the QuakeML file using ObsPy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     catalog \u001b[38;5;241m=\u001b[39m read_events(quakeml_file)\n\u001b[1;32m      5\u001b[0m     entries \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m catalog:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# Extract basic event information\u001b[39;00m\n",
      "File \u001b[0;32m~/Programs/anaconda3/lib/python3.11/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/Programs/anaconda3/lib/python3.11/site-packages/obspy/core/util/decorator.py:297\u001b[0m, in \u001b[0;36mmap_example_filename.<locals>._map_example_filename\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m                     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Programs/anaconda3/lib/python3.11/site-packages/obspy/core/event/catalog.py:810\u001b[0m, in \u001b[0;36mread_events\u001b[0;34m(pathname_or_url, format, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _create_example_catalog()\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _generic_reader(pathname_or_url, _read, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Programs/anaconda3/lib/python3.11/site-packages/obspy/core/util/base.py:656\u001b[0m, in \u001b[0;36m_generic_reader\u001b[0;34m(pathname_or_url, callback_func, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file matching file pattern: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m pathname)\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mhas_magic(pathname) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(pathname)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m--> 656\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m, pathname)\n\u001b[1;32m    658\u001b[0m generic \u001b[38;5;241m=\u001b[39m callback_func(pathnames[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pathnames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/CATALOG/CMTSOLUTIONS_2010_2025.xml'"
     ]
    }
   ],
   "source": [
    "print('===============')\n",
    "print('Reading catalog')\n",
    "print('===============')\n",
    "print('\\n')\n",
    "\n",
    "cat = quakeml_to_dataframe(CATALOG_FILE)\n",
    "cat.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8d55cd-c32e-48dc-a5fa-d249eb0d8583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Reading stations\n",
      "================\n",
      "\n",
      "\n",
      "Number of stations: 1\n"
     ]
    }
   ],
   "source": [
    "print('================')\n",
    "print('Reading stations')\n",
    "print('================')\n",
    "print('\\n')\n",
    "\n",
    "STATIONS_xml = sorted(glob.glob(XML_DIR+'*BR.CZ*'))\n",
    "print('Number of stations:',len(STATIONS_xml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4eb8bf-7618-4643-987f-deb4973dffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/BR.CZSB.dataless.xml']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATIONS_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7b533b-87e8-4340-8c5b-0e559f84ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_orientation(input_lst):\n",
    "\n",
    "    xml_file = input_lst[0]\n",
    "    wave_dir = input_lst[1]\n",
    "    \n",
    "    # ---------------\n",
    "    # Read XML file\n",
    "                        \n",
    "    station_xml = op.read_inventory(xml_file)\n",
    "    network = station_xml[0].code\n",
    "    station = station_xml[0][0].code    \n",
    "    \n",
    "    # ---------------------------\n",
    "    # Retrieving events waveforms\n",
    "    # ---------------------------\n",
    "    \n",
    "    for evid,event in tqdm(cat.iterrows(), total=len(cat),desc=station+' orientation'):\n",
    "        # ------------------------------\n",
    "        # Check if the event is eligible\n",
    "\n",
    "        evdp = event['depth']\n",
    "        evmag = event['mag']\n",
    "        evtype = event['magType']\n",
    "        evtime = UTCDateTime(event['time'])\n",
    "        evname = UTCDateTime(event['time']).strftime('%Y.%j.%H.%M.%S')\n",
    "        evname2 = UTCDateTime(event['time']).strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        year = UTCDateTime(event['time']).strftime('%Y')\n",
    "        julian_day = UTCDateTime(event['time']).strftime('%j')\n",
    "                            \n",
    "        # Epicentral distance:\n",
    "            \n",
    "        stlo = station_xml[-1][-1][-1].longitude\n",
    "        stla = station_xml[-1][-1][-1].latitude\n",
    "            \n",
    "        evla = event['latitude']\n",
    "        evlo = event['longitude']\n",
    "            \n",
    "        dist,az,baz = gps2dist_azimuth(evla, evlo,stla, stlo)\n",
    "        gcarc = kilometers2degrees(dist/1000)\n",
    "        \n",
    "        # Taup: theoretical travel times \n",
    "        model = TauPyModel(model=\"iasp91\")\n",
    "        arrivals = model.get_travel_times(source_depth_in_km=evdp,distance_in_degree=gcarc,phase_list=['P','PKP','PKIKP'])\n",
    "        \n",
    "        if len(arrivals) > 0 and (gcarc < 100 or 140 < gcarc <= 180):\n",
    "            \n",
    "            # Event time + phase arrival time\n",
    "            evtime = evtime+arrivals[0].time\n",
    "            \n",
    "            # ----------------------------\n",
    "            # Check if feather file exists\n",
    "            \n",
    "            output_FEATHER_FILES_ORIENTATION = ORIENTATION_OUTPUT+'FEATHER_FILES/ORIENTATION/'+network+'.'+station+'/'\n",
    "            \n",
    "            file_feather_name = output_FEATHER_FILES_ORIENTATION+network+'.'+station+'.'+evname+'.orientation.feather'\n",
    "    \n",
    "            station_pwd = glob.glob(wave_dir + '/*')\n",
    "   \n",
    "            if os.path.isfile(file_feather_name):\n",
    "                pass\n",
    "        \n",
    "            else:\n",
    "                # -------------------------------\n",
    "                # Check if components file exists\n",
    "                        \n",
    "                if 1 == 1:    \n",
    "\n",
    "                    files = [x for x in station_pwd if x.endswith(evname2)]\n",
    "\n",
    "                    if len(files) >= 3:\n",
    "                        try:\n",
    "                            file_HHE = files[component_index(files, \"E\")]\n",
    "                            file_HHN = files[component_index(files, \"N\")]\n",
    "                            file_HHZ = files[component_index(files, \"Z\")]\n",
    "\n",
    "                        except:\n",
    "\n",
    "                            file_HHE = files[component_index(files, \"2\")]\n",
    "                            file_HHN = files[component_index(files, \"1\")]\n",
    "                            file_HHZ = files[component_index(files, \"Z\")]\n",
    "\n",
    "            \n",
    "                        # # # --------\n",
    "                        # # # Data HHE\n",
    "                                \n",
    "                        tr2_data_file = op.read(file_HHE)\n",
    "                        tr2_data_file.trim(evtime-TIME_WINDOW,evtime+TIME_WINDOW)\n",
    "                        tr2_data_file.taper(type='cosine',max_percentage=0.1)\n",
    "                        tr2_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                    \n",
    "                        # --------\n",
    "                        # Data HHN\n",
    "                    \n",
    "                        tr1_data_file = op.read(file_HHN)\n",
    "                        tr1_data_file.trim(evtime-TIME_WINDOW,evtime+TIME_WINDOW)\n",
    "                        tr1_data_file.taper(type='cosine',max_percentage=0.1)\n",
    "                        tr1_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                            \n",
    "                        # --------\n",
    "                        # Data HHZ\n",
    "                                \n",
    "                        trZ_data_file = op.read(file_HHZ)\n",
    "                        trZ_data_file.trim(evtime-TIME_WINDOW,evtime+TIME_WINDOW)\n",
    "                        trZ_data_file.taper(type='cosine',max_percentage=0.1)\n",
    "                        trZ_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "\n",
    "                        if len(tr2_data_file) > 0 and len(tr1_data_file) > 0 and len(trZ_data_file) > 0:\n",
    "                               \n",
    "                             if (tr2_data_file[0].stats.npts == tr1_data_file[0].stats.npts == trZ_data_file[0].stats.npts) and (trZ_data_file[0].stats.npts > TIME_WINDOW * 40):\n",
    "                                \n",
    "                                tr2_data_filtered = tr2_data_file[0].data[1000:-1000]\n",
    "            \n",
    "                                tr1_data_filtered = tr1_data_file[0].data[1000:-1000]\n",
    "                                    \n",
    "                                trZ_data_filtered = trZ_data_file[0].data[1000:-1000]\n",
    "                                trZ_time = trZ_data_file[0].times()[1000:-1000]-TIME_WINDOW\n",
    "\n",
    "                                # -------------------------------------------\n",
    "                                # Function estimates the Akaike Information directly from data \n",
    "                                # The Summed Log Likelihood section implies that a natural \n",
    "                                # changepoint estimate is the sample index that minimizes \n",
    "                                # the AIC in equation\n",
    "                                \n",
    "                                aic_curve = aic_simple(trZ_data_filtered)\n",
    "                                \n",
    "                                k_min_index = np.argmin(aic_curve)\n",
    "                            \n",
    "                                time_P_arr = trZ_time[k_min_index]\n",
    "                                                        \n",
    "                                # Time error:\n",
    "                                time_ins = round(time_P_arr,1)\n",
    "                            \n",
    "                                if time_ins > 0:\n",
    "                                    signal_window_start = time_ins\n",
    "                                    signal_window_final = time_ins+TIME_FINAL_P\n",
    "                                    noise_window_start = time_ins\n",
    "                                    noise_window_final = time_ins-TIME_FINAL_P\n",
    "                                else:\n",
    "                                    signal_window_start = time_ins\n",
    "                                    signal_window_final = TIME_FINAL_P+time_ins\n",
    "                                    noise_window_start = time_ins\n",
    "                                    noise_window_final = -(abs(time_ins)+TIME_FINAL_P) \n",
    "                                # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                                # Signal and noise windows\n",
    "                                        \n",
    "                                signal_window = (trZ_time >= signal_window_start) & (trZ_time <= signal_window_final)\n",
    "                                noise_window = (trZ_time >= noise_window_final) & (trZ_time <= noise_window_start)\n",
    "                                \n",
    "                                noise = trZ_data_filtered[noise_window]\n",
    "                                trZ_noise_time = trZ_time[noise_window]\n",
    "            \n",
    "                                tr2 = tr2_data_filtered[signal_window]\n",
    "                                tr1 = tr1_data_filtered[signal_window]\n",
    "                                trZ = trZ_data_filtered[signal_window]\n",
    "                                trZ_signal_time = trZ_time[signal_window]\n",
    "                                    \n",
    "                                # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                                # Calculating the optimal orientation\n",
    "                                                    \n",
    "                                results = Braunmiller_Pornsopin_algorithm(tr1,tr2,trZ,noise,baz,time_ins,CCVR_MIN=0.45,SNR_MIN=10,TRR_MIN=0.45,RVR_MIN=-1)\n",
    "\n",
    "                                # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                                # Calculating the Plunge of: P, B, and T axis\n",
    "\n",
    "                                nodal_planes = moment_tensor_to_nodal_planes(event['moment tensor'])\n",
    "\n",
    "                                event_class = mecclass(nodal_planes)\n",
    "\n",
    "                                # ----------------------------------------------------------------------------------------------------                               \n",
    "                                # Creating a Pandas DataFrame:\n",
    "                                column_info = [network,station,stla,stlo,evname,evla,evlo,evtime,evmag,evtype,evdp,dist,gcarc,baz,tr1_data_filtered,tr2_data_filtered,trZ_data_filtered,trZ_time,results['SS_best'],results['signal_strength'],results['SZR_best'],results['similarity_ZR'],results['ERTR_best'],results['energy_ratio_TR'],results['ERRZ_best'],results['energy_ratio_RZ'],results['SNR'],results['phi'],results['theta'],aic_curve,time_ins,results['quality'],results['gain_HHN'],results['gain_HHE'],results['gain_HHZ'],event['moment tensor'],nodal_planes,event_class]\n",
    "                                columns_header = ['network','station','stla','stlo','evname','evla','evlo','evtime','evmag','evtype','evdp','distance','gcarc','baz','tr1_data','tr2_data','trZ_data','trZ_time','SS_best','signal_strength','SZR_best','similarity_vertical_radial','ERTR_best','energy_transverse_radial','ERRZ_best','energy_radial_vertical','SNR','phi','theta','aic_curve','clock_error','quality','gain_HHN','gain_HHE','gain_HHZ','moment tensor','nodal_planes','event_class']\n",
    "                                orient_p_wave_df = pd.DataFrame(column_info, index=columns_header).T\n",
    "                                orient_p_wave_df['evtime'] = pd.to_datetime(orient_p_wave_df['evtime'].apply(lambda x: x.isoformat() if isinstance(x, UTCDateTime) else x))\n",
    "\n",
    "                                # ----------------------------------------------------------------------------------------------------\n",
    "                                # Convert from pandas to Arrow and saving in feather formart file\n",
    "                                os.makedirs(output_FEATHER_FILES_ORIENTATION,exist_ok=True)\n",
    "                                feather.write_feather(orient_p_wave_df, file_feather_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28368e53-7a2d-4acd-a368-aef64c5149ed",
   "metadata": {},
   "source": [
    "# Creating input list for different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c632f4-5e97-4fcd-b2e8-4cf0a7c39893",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for xml_f in STATIONS_xml:\n",
    "    for wa_dir in WAVEFORM_DIR:\n",
    "        input_list.append([xml_f,wa_dir])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65bd7c8-bc78-4c49-a91c-4284c239e6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/BR.CZSB.dataless.xml',\n",
       "  '/medata01/SEISCOMP_DATA/'],\n",
       " ['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/BR.CZSB.dataless.xml',\n",
       "  '/medata02/SEISCOMP_DATA/'],\n",
       " ['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/BR.CZSB.dataless.xml',\n",
       "  '/medata03/SEISCOMP_DATA/']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7aaff42-f461-40c1-90ff-78c6b83e6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CZSB orientation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2050/2050 [01:41<00:00, 20.11it/s]\n",
      "CZSB orientation:  48%|█████████████████████████████████████████████████████████████████████████▏                                                                             | 993/2050 [12:46<1:07:37,  3.84s/it]/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=-1238026302, Xn=22369621\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=-2101478795, Xn=22369621\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=-1358410873, Xn=22369621\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=-988189950, Xn=809055030\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=556182648, Xn=22369621\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=-772816339, Xn=22369621\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py:805: InternalMSEEDWarning: BR_CZSB__HHN_D: Warning: Data integrity check for Steim1 failed, Last sample=-1073902539, Xn=842348086\n",
      "  warnings.warn(_w, InternalMSEEDWarning)\n",
      "CZSB orientation:  48%|██████████████████████████████████████████████████████████████████████████▏                                                                              | 994/2050 [12:49<13:37,  1.29it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [12:49<00:00, 769.08s/it]\n"
     ]
    },
    {
     "ename": "InternalMSEEDError",
     "evalue": "Encountered 7 error(s) during a call to readMSEEDBuffer():\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 156 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 152 samples of 392 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 121 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 125 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 147 samples of 370 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 147 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 120 samples of 412 expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_8414/908269141.py\", line 82, in calculate_orientation\n    tr2_data_file = op.read(file_HHE)\n                    ^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/core/util/decorator.py\", line 297, in _map_example_filename\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/core/stream.py\", line 208, in read\n    st = _generic_reader(pathname_or_url, _read, **kwargs)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/core/util/base.py\", line 658, in _generic_reader\n    generic = callback_func(pathnames[0], **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/decorator.py\", line 232, in fun\n    return caller(func, *(extras + args), **kw)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/core/util/decorator.py\", line 208, in uncompress_file\n    result = func(filename, *args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/core/stream.py\", line 251, in _read\n    stream, format = _read_from_plugin('waveform', filename, format=format,\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/core/util/base.py\", line 423, in _read_from_plugin\n    list_obj = read_format(filename, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/core.py\", line 398, in _read_mseed\n    lil = clibmseed.readMSEEDBuffer(\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/sysop/Programs/anaconda3/lib/python3.12/site-packages/obspy/io/mseed/headers.py\", line 810, in _wrapper\n    raise InternalMSEEDError(msg)\nobspy.io.mseed.InternalMSEEDError: Encountered 7 error(s) during a call to readMSEEDBuffer():\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 156 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 152 samples of 392 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 121 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 125 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 147 samples of 370 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 147 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 120 samples of 412 expected\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInternalMSEEDError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     max_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(STATIONS_xml)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mmax_,) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m p\u001b[38;5;241m.\u001b[39mimap_unordered(calculate_orientation,input_list):\n\u001b[1;32m      7\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Programs/anaconda3/lib/python3.12/multiprocessing/pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mInternalMSEEDError\u001b[0m: Encountered 7 error(s) during a call to readMSEEDBuffer():\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 156 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 152 samples of 392 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 121 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 125 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 147 samples of 370 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 147 samples of 412 expected\nmsr_unpack_data(BR_CZSB__HHN_D): only decoded 120 samples of 412 expected"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with Pool(processes=num_processes) as p:\n",
    "    max_ = len(STATIONS_xml)\n",
    "    with tqdm(total=max_,) as pbar:\n",
    "        for result in p.imap_unordered(calculate_orientation,input_list):\n",
    "            pbar.update()\n",
    "\n",
    "print('\\n')\n",
    "print(\"--- %.2f execution time (min) ---\" % ((time.time() - start_time)/60))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a13f6-a6e7-45bb-99a6-904caa2df3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
