{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d40e58e-efc2-4947-b808-455c3a239acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn import preprocessing\n",
    "from obspy.signal.headers import clibsignal\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.dates import YearLocator, MonthLocator, DayLocator, HourLocator, MinuteLocator, SecondLocator, DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import obspy as op\n",
    "from obspy import read,read_inventory, UTCDateTime, Stream, Trace\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.signal.rotate import rotate_ne_rt\n",
    "from obspy.geodetics import gps2dist_azimuth,kilometers2degrees\n",
    "from obspy.taup import TauPyModel\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from scipy.signal import spectrogram, detrend, resample,savgol_filter,decimate,hilbert\n",
    "from scipy.stats import circmean, circstd\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adcd26-b9a9-45b2-ac84-3b7fa5358563",
   "metadata": {},
   "source": [
    "____________\n",
    "# Setup\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e400d2-d641-4abb-8f26-6ec9b323bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========\n",
    "# DIRECTORIES\n",
    "# ===========\n",
    "\n",
    "## ------------------------\n",
    "## Directory with waveforms (SeisComP Data Structure)\n",
    "## The basic directory and file layout is defined as:\n",
    "## <SDSdir>/Year/NET/STA/CHAN.TYPE/NET.STA.LOC.CHAN.TYPE.YEAR.DAY\n",
    "\n",
    "WAVEFORM_DIR = ['/medata01/SEISCOMP_DATA/','/medata02/SEISCOMP_DATA/','/medata03/SEISCOMP_DATA/']\n",
    "\n",
    "## ---------------------------\n",
    "## Directory with the catalog (.CSV file of the National Earthquake Information Center (NEIC))\n",
    "## The file layout is defined as:\n",
    "## time,latitude,longitude,depth,mag,magType,nst,gap,dmin,rms,net,id,updated,place,type,horizontalError,depthError,magError,magNst,status,locationSource,magSource\n",
    "\n",
    "CATALOG_FILE = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/CATALOG/catalog_2010_2025.csv'\n",
    "\n",
    "## ----------------------------\n",
    "## Directory of the StationXML:\n",
    "\n",
    "XML_DIR = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/'\n",
    "\n",
    "## -----------------------\n",
    "## Directory of the output (Figures and Feathers file)\n",
    "\n",
    "ORIENTATION_OUTPUT = '/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/OUTPUT/'\n",
    "\n",
    "# ==========\n",
    "# PARAMETERS\n",
    "# ==========\n",
    "\n",
    "## -------------------------------------------------------------------\n",
    "## Apply band-pass filtering to the seismograms using the range above:\n",
    "\n",
    "PERIOD_BANDS = [0.02,0.5]\n",
    "\n",
    "## ===================================================================================\n",
    "## Default parameters to define the signal and noise windows used to estimate the SNR:\n",
    "\n",
    "## ------------------------------------------------------------------------------\n",
    "## Duration of the signal window before and after the P-wave arrival (in seconds)\n",
    "\n",
    "TIME_WINDOW = 120\n",
    "\n",
    "## ---------------------------------------------------------------\n",
    "## P-wave time window for events (in seconds after P-wave arrival)\n",
    "\n",
    "TIME_FINAL_P = 15\n",
    "\n",
    "## ---------------------------------------------\n",
    "## Minimum earthquake magnitude to be considered\n",
    "\n",
    "minmagnitude = 6\n",
    "\n",
    "## -------------------------------------------------------------------------------------\n",
    "## Minimum and maximum epicentral distance in degrees (GCARC: great-circle arc distance)\n",
    "\n",
    "GCARC_MIN = 5\n",
    "GCARC_MAX = 100\n",
    "\n",
    "## -----------------\n",
    "## Region parameters\n",
    "\n",
    "LLCRNRLON_LARGE = -50\n",
    "URCRNRLON_LARGE = -38\n",
    "LLCRNRLAT_LARGE = -30\n",
    "URCRNRLAT_LARGE = -12\n",
    "\n",
    "## ---------\n",
    "## Constants\n",
    "\n",
    "ONEDAY = datetime.timedelta(days=1)\n",
    "\n",
    "## ---------------\n",
    "## MULTIPROCESSING\n",
    "\n",
    "num_processes = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8131ee-42db-44ad-aedf-c11a8e44fe5d",
   "metadata": {},
   "source": [
    "---\n",
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48373d9-8612-453e-8541-b524a99126fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(x):\n",
    "    \"\"\"\n",
    "    Function to calculate root-mean-square of array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :class:`~numpy.ndarray`\n",
    "        Input array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rms : float\n",
    "        Root-Mean-Square value of `x`\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "\n",
    "def energy(x):\n",
    "    \"\"\"\n",
    "    Function to calculate energy of array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : :class:`~numpy.ndarray`\n",
    "        Input array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    energy : float\n",
    "        Square value of `x`\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sum(x**2)\n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def aic_simple(a):\n",
    "    r\"\"\"\n",
    "    Simple Akaike Information Criterion [Maeda1985]_.\n",
    "\n",
    "    It's computed directly from input data :math:`a` and defined as\n",
    "\n",
    "    .. math::\n",
    "        \\text{AIC}(k) = k\\log(\\text{Var}(a_{1..k})) +\n",
    "                        (N-k-1)\\log(\\text{Var}(a_{k+1..N}))\n",
    "\n",
    "    which variance denoted as :math:`\\text{Var}`.\n",
    "\n",
    "    The true output is one data sample less. To make it convenient with other\n",
    "    metrics in this module, where the output length is preserved, the last\n",
    "    element is appended to the output: ``aic[-2] == aic[-1]``.\n",
    "\n",
    "    :type a: :class:`numpy.ndarray` or :class:`list`\n",
    "    :param a: Input time series\n",
    "    :rtype: :class:`numpy.ndarray`\n",
    "    :return: aic - Akaike Information Criterion array\n",
    "    \"\"\"\n",
    "    n = len(a)\n",
    "    if n <= 2:\n",
    "        return np.zeros(n, dtype=np.float64)\n",
    "    a = np.ascontiguousarray(a, np.float64)\n",
    "    aic_res = np.empty(n, dtype=np.float64)\n",
    "    clibsignal.aic_simple(aic_res, a, n)\n",
    "    return aic_res\n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "def find_orientation(baz,SS,SZR,ERTR,ERRZ):\n",
    "\n",
    "    \"\"\"\n",
    "    This function calculates the best back azimuth (phi) and sensor misorientation (theta) based on the \n",
    "    given quality criteria: signal strength (SS), similarity of vertical and radial components (SZR), \n",
    "    transverse-to-radial energy ratio (ERTR), and radial-to-vertical energy ratio (ERRZ).\n",
    "\n",
    "    The cost function combines these criteria in such a way that maximizing the cost function helps to\n",
    "    find the optimal back azimuth and corresponding orientation. The function outputs the best back azimuth, orientation,\n",
    "    and the values of the quality criteria at the best azimuth index.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    baz : float\n",
    "        Initial back azimuth value from the taup model (degrees).\n",
    "    SS : np.array\n",
    "        Array of signal strength values for each azimuth angle.\n",
    "    SZR : np.array\n",
    "        Array of similarity values between vertical and radial components for each azimuth angle.\n",
    "    ERTR : np.array\n",
    "        Array of transverse-to-radial energy ratios for each azimuth angle.\n",
    "    ERRZ : np.array\n",
    "        Array of radial-to-vertical energy ratios for each azimuth angle.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    phi : float\n",
    "        The best back azimuth angle (degrees) that minimizes the cost function.\n",
    "    theta : float\n",
    "        The sensor misorientation angle (degrees), defined as the difference between the true back azimuth \n",
    "        and the estimated back azimuth.\n",
    "    SS_best : float\n",
    "        The signal strength value at the best azimuth.\n",
    "    SZR_best : float\n",
    "        The similarity between vertical and radial components at the best azimuth.\n",
    "    ERTR_best : float\n",
    "        The transverse-to-radial energy ratio at the best azimuth.\n",
    "    ERRZ_best : float\n",
    "        The radial-to-vertical energy ratio at the best azimuth.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find best index\n",
    "    cost_function = (\n",
    "                (1-SS) +  # Minimizing energy (equal to Maximizing (1 - transversal energy))\n",
    "                SZR +     # Maximizing similarity\n",
    "                ERTR    # Maximizing transverse-to-radial ratio\n",
    "                    )\n",
    "    \n",
    "    # Best index will maximize the cost function                    \n",
    "    best_index = np.argmax(cost_function)\n",
    "    \n",
    "    # --------------------\n",
    "    # Search Space of BAZ\n",
    "\n",
    "    # Step size for the azimuth search (in degrees).\n",
    "    dphi = 0.1\n",
    "\n",
    "    # Array of azimuth angles to search through (in degrees).\n",
    "    ang = np.arange(0., 360., dphi)\n",
    "                            \n",
    "    # Get azimuth and correct for angles above 360\n",
    "    phi = round(ang[best_index])\n",
    "    theta = round(baz - ang[best_index])\n",
    "\n",
    "    # Expressed as a deviation from North\n",
    "    theta = theta % 360          # Convert to (0°, 360°)\n",
    "    if theta > 180:              \n",
    "        theta -= 360             # Convert to (-180°, 180°)\n",
    "                            \n",
    "    # Get argument of maximum coherence:\n",
    "    SS_best = SS[best_index]\n",
    "    SZR_best = SZR[best_index]\n",
    "    ERTR_best = ERTR[best_index]\n",
    "    ERRZ_best = ERRZ[best_index]\n",
    "\n",
    "    return phi,theta,SS_best,SZR_best,ERTR_best,ERRZ_best\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def Braunmiller_Pornsopin_algorithm(tr1,tr2,trZ,noise,baz,time_ins,CCVR_MIN=0.45,SNR_MIN=10,TRR_MIN=0.45,RVR_MIN=-1):\n",
    "\n",
    "    \"\"\"\n",
    "    Estimate back azimuth using P-wave particle motion and apply quality criteria.\n",
    "\n",
    "    This algorithm estimates the back azimuth by analyzing P-wave particle motion in an isotropic, \n",
    "    homogeneous layered medium. In such a medium, the P-wave energy propagates along a great circle \n",
    "    path between the source and receiver, with horizontal components defining the radial direction.\n",
    "    The angle between the radial direction and true north gives the back azimuth. The P-wave energy \n",
    "    is confined to the vertical and radial components, with no energy in the transverse component.\n",
    "\n",
    "    The sensor 'misorientation angle' is the difference between the true back azimuth (from the taup model) \n",
    "    and the empirically estimated back azimuth, with positive values representing a clockwise misorientation.\n",
    "\n",
    "    This method applies several quality criteria to filter out unreliable results from component malfunctions or \n",
    "    missing horizontal components:\n",
    "    \n",
    "    == Quality criteria for automatic processing ==\n",
    "\n",
    "    To select reliable back azimuths in automatic processing, the following five quality criteria are applied:\n",
    "     - (1) Overall signal strength of the radial component.\n",
    "     - (2) Similarity between the vertical and radial components.\n",
    "     - (3) Transverse-to-radial energy ratio.\n",
    "     - (4) Radial-to-vertical energy ratio.\n",
    "     - (5) Signal-to-noise ratio (SNR) on the vertical component.\n",
    "\n",
    "    The function uses these criteria to assess the quality of the estimated back azimuth, and classifies the result \n",
    "    as 'good' or 'bad' based on the user-defined thresholds.\n",
    "\n",
    "    -----------  \n",
    "    Parameters:\n",
    "    ----------\n",
    "    tr1 : np.array\n",
    "        The first horizontal component of the seismogram.\n",
    "    tr2 : np.array\n",
    "        The second horizontal component of the seismogram.\n",
    "    trZ : np.array\n",
    "        The vertical component of the seismogram.\n",
    "    noise : np.array\n",
    "        Noise window to calculate the signal-to-noise ratio (SNR).\n",
    "    baz : float\n",
    "        Back azimuth from the taup model (in degrees).\n",
    "    time_ins : float\n",
    "        Difference between observed and predicted travel time\n",
    "        using available data of distant earthquake (in seconds).\n",
    "    CCVR_MIN : float, optional\n",
    "        Minimum required similarity of vertical and radial components (default is 0.45).\n",
    "    SNR_MIN : float, optional\n",
    "        Minimum required signal-to-noise ratio (default is 10).\n",
    "    TRR_MIN : float, optional\n",
    "        Minimum required transverse-to-radial energy ratio (default is 0.45).\n",
    "    RVR_MIN : float, optional\n",
    "        Minimum allowed radial-to-vertical energy ratio (default is -1).\n",
    "        \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing the following calculated quality criteria, estimated azimuth, and additional results:\n",
    "        \n",
    "        - 'phi' : float\n",
    "            The estimated back azimuth angle (in degrees) based on the best-fit azimuth search.\n",
    "        \n",
    "        - 'baz' : float\n",
    "            The true back azimuth (in degrees) from the taup model, which serves as a reference for comparison with the estimated azimuth.\n",
    "        \n",
    "        - 'SNR' : float\n",
    "            The signal-to-noise ratio (SNR) of the vertical component, expressed in decibels (dB), representing the strength of the signal relative to noise.\n",
    "        \n",
    "        - 'quality' : str\n",
    "            A classification of the estimated azimuth quality ('good' or 'bad'), based on the comparison of various quality criteria and thresholds.\n",
    "        \n",
    "        - 'theta' : float\n",
    "            The sensor misorientation angle (in degrees), representing the difference between the true back azimuth (from the taup model) and the empirically estimated azimuth.\n",
    "        \n",
    "        - 'SS_best' : float\n",
    "            The best signal strength value for the optimal azimuth, quantifying the energy of the radial component for the best-fit azimuth.\n",
    "        \n",
    "        - 'SZR_best' : float\n",
    "            The best similarity score between the vertical and radial components for the optimal azimuth, indicating how well the vertical and radial components align.\n",
    "        \n",
    "        - 'ERTR_best' : float\n",
    "            The best transverse-to-radial energy ratio for the optimal azimuth, assessing the degree to which the transverse component contaminates the radial component.\n",
    "        \n",
    "        - 'ERRZ_best' : float\n",
    "            The best radial-to-vertical energy ratio for the optimal azimuth, showing the relative strength of the radial component compared to the vertical component.\n",
    "        \n",
    "        - 'signal_strength' : np.array\n",
    "            A NumPy array containing the signal strength values for each azimuth tested in the search range, reflecting the overall energy of the radial component.\n",
    "        \n",
    "        - 'similarity_ZR' : np.array\n",
    "            A NumPy array containing the similarity (correlation) coefficients between the vertical and radial components for each azimuth tested.\n",
    "        \n",
    "        - 'energy_ratio_TR' : np.array\n",
    "            A NumPy array containing the transverse-to-radial energy ratios for each azimuth tested, evaluating the amount of transverse energy relative to radial energy.\n",
    "        \n",
    "        - 'energy_ratio_RZ' : np.array\n",
    "            A NumPy array containing the radial-to-vertical energy ratios for each azimuth tested, indicating how much radial energy is present compared to vertical energy.\n",
    "    \n",
    "    Notes:\n",
    "    ------\n",
    "    The algorithm assumes that the back azimuth is between 0 and 360 degrees and that the sensor \n",
    "    misorientation is defined as the difference between the true back azimuth and the empirically estimated back azimuth.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --------------------\n",
    "    # Search Space of BAZ\n",
    "\n",
    "    # Step size for the azimuth search (in degrees).\n",
    "    dphi = 0.1\n",
    "\n",
    "    # Array of azimuth angles to search through (in degrees).\n",
    "    ang = np.arange(0., 360., dphi)\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Initialize quality criteria\n",
    "    \n",
    "    signal_strength = np.zeros(len(ang))\n",
    "    similarity_ZR = np.zeros(len(ang))\n",
    "    energy_ratio_TR = np.zeros(len(ang))\n",
    "    energy_ratio_RZ = np.zeros(len(ang))\n",
    "  \n",
    "    # Search through azimuths and find best-fit azimuth\n",
    "    for k, an in enumerate(ang):\n",
    "        R, T = rotate_ne_rt(tr1, tr2, an)\n",
    "\n",
    "        # (1) Overall signal strength of the transversal component\n",
    "        signal_strength[k] = energy(T)\n",
    "\n",
    "        # (2) Similarity of vertical and radial components\n",
    "        similarity_ZR[k] = np.corrcoef(trZ, R)[0, 1]\n",
    "        \n",
    "        # (3) Transverse-to-radial energy ratio\n",
    "        energy_ratio_TR[k] = 1-energy(T) / energy(R)\n",
    "        \n",
    "        # (4) Radial-to-vertical energy ratio\n",
    "        energy_ratio_RZ[k] = 1-energy(R) / energy(trZ)  \n",
    "    \n",
    "    # (5) Signal-to-noise ratio on vertical component\n",
    "    SNR = round(10.0 * np.log10(rms(trZ)**2 / rms(noise)**2), 1)\n",
    "\n",
    "    # Normalizing the signal strength of the transversal component\n",
    "    signal_strength = (signal_strength - np.min(signal_strength)) / (np.max(signal_strength) - np.min(signal_strength)) \n",
    "    energy_ratio_TR = (energy_ratio_TR - np.min(energy_ratio_TR)) / (np.max(energy_ratio_TR) - np.min(energy_ratio_TR)) \n",
    "\n",
    "    phi,theta,SS_best,SZR_best,ERTR_best,ERRZ_best = find_orientation(baz,signal_strength,similarity_ZR,energy_ratio_TR,energy_ratio_RZ)\n",
    "\n",
    "    if (SZR_best >= CCVR_MIN) & (SNR >= SNR_MIN) & (ERTR_best >= TRR_MIN) & (ERRZ_best >= RVR_MIN) &  (-90 < time_ins < 90):\n",
    "        quality = 'good'\n",
    "    else:\n",
    "        quality = 'bad'\n",
    "\n",
    "    # Collect results\n",
    "    results = {\n",
    "        'phi': phi,\n",
    "        'baz': baz,\n",
    "        'SNR': SNR,\n",
    "        'quality': quality,\n",
    "        'theta': theta,\n",
    "        'SS_best': SS_best,\n",
    "        'SZR_best': SZR_best,\n",
    "        'ERTR_best': ERTR_best,\n",
    "        'ERRZ_best': ERRZ_best,\n",
    "        'signal_strength': signal_strength,\n",
    "        'similarity_ZR': similarity_ZR,\n",
    "        'energy_ratio_TR': energy_ratio_TR,\n",
    "        'energy_ratio_RZ': energy_ratio_RZ,\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c48e567-c721-45f0-ae93-c26b63ecec53",
   "metadata": {},
   "source": [
    "---\n",
    "# Main program\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5816da9d-0a59-47f2-913b-920bfea570e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "Reading catalog\n",
      "===============\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>2025-03-10T02:33:14.389Z</td>\n",
       "      <td>71.1971</td>\n",
       "      <td>-8.1925</td>\n",
       "      <td>10.000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>mww</td>\n",
       "      <td>69.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.587</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-03-11T02:57:16.212Z</td>\n",
       "      <td>36 km NNE of Olonkinbyen, Svalbard and Jan Mayen</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.78</td>\n",
       "      <td>1.899</td>\n",
       "      <td>0.041</td>\n",
       "      <td>58.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2025-03-14T23:42:35.671Z</td>\n",
       "      <td>-55.7385</td>\n",
       "      <td>-27.1122</td>\n",
       "      <td>35.379</td>\n",
       "      <td>6.0</td>\n",
       "      <td>mww</td>\n",
       "      <td>71.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5.589</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-03-16T23:53:17.562Z</td>\n",
       "      <td>South Sandwich Islands region</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>10.47</td>\n",
       "      <td>6.746</td>\n",
       "      <td>0.093</td>\n",
       "      <td>11.0</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time  latitude  longitude   depth  mag magType  \\\n",
       "2156  2025-03-10T02:33:14.389Z   71.1971    -8.1925  10.000  6.5     mww   \n",
       "2157  2025-03-14T23:42:35.671Z  -55.7385   -27.1122  35.379  6.0     mww   \n",
       "\n",
       "       nst   gap   dmin   rms  ...                   updated  \\\n",
       "2156  69.0  44.0  4.587  1.23  ...  2025-03-11T02:57:16.212Z   \n",
       "2157  71.0  68.0  5.589  0.91  ...  2025-03-16T23:53:17.562Z   \n",
       "\n",
       "                                                 place        type  \\\n",
       "2156  36 km NNE of Olonkinbyen, Svalbard and Jan Mayen  earthquake   \n",
       "2157                     South Sandwich Islands region  earthquake   \n",
       "\n",
       "     horizontalError depthError  magError  magNst    status  locationSource  \\\n",
       "2156            7.78      1.899     0.041    58.0  reviewed              us   \n",
       "2157           10.47      6.746     0.093    11.0  reviewed              us   \n",
       "\n",
       "     magSource  \n",
       "2156        us  \n",
       "2157        us  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('===============')\n",
    "print('Reading catalog')\n",
    "print('===============')\n",
    "print('\\n')\n",
    "\n",
    "cat = pd.read_csv(CATALOG_FILE)\n",
    "cat.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8d55cd-c32e-48dc-a5fa-d249eb0d8583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "Reading stations\n",
      "================\n",
      "\n",
      "\n",
      "Number of stations: 1\n"
     ]
    }
   ],
   "source": [
    "print('================')\n",
    "print('Reading stations')\n",
    "print('================')\n",
    "print('\\n')\n",
    "\n",
    "STATIONS_xml = sorted(glob.glob(XML_DIR+'*NB.NBCL*'))\n",
    "print('Number of stations:',len(STATIONS_xml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4eb8bf-7618-4643-987f-deb4973dffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/NB.NBCL.ds.xml']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATIONS_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7b533b-87e8-4340-8c5b-0e559f84ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_orientation(input_lst):\n",
    "\n",
    "    xml_file = input_lst[0]\n",
    "    wave_dir = input_lst[1]\n",
    "    # ---------------\n",
    "    # Read XML file\n",
    "                        \n",
    "    station_xml = op.read_inventory(xml_file)\n",
    "    network = station_xml[0].code\n",
    "    station = station_xml[0][0].code    \n",
    "    \n",
    "    # ---------------------------\n",
    "    # Retrieving events waveforms\n",
    "    # ---------------------------\n",
    "    \n",
    "    for evid,event in tqdm(cat.iterrows(), total=len(cat),desc=station+' orientation'):\n",
    "        # ------------------------------\n",
    "        # Check if the event is eligible\n",
    "\n",
    "        evdp = event['depth']\n",
    "        evmag = event['mag']\n",
    "        evtype = event['magType']\n",
    "        evtime = UTCDateTime(event['time'])\n",
    "        evname = UTCDateTime(event['time']).strftime('%Y.%j.%H.%M.%S')\n",
    "\n",
    "        year = UTCDateTime(event['time']).strftime('%Y')\n",
    "        julian_day = UTCDateTime(event['time']).strftime('%j')\n",
    "                            \n",
    "        # Epicentral distance:\n",
    "            \n",
    "        stlo = station_xml[-1][-1][-1].longitude\n",
    "        stla = station_xml[-1][-1][-1].latitude\n",
    "            \n",
    "        evla = event['latitude']\n",
    "        evlo = event['longitude']\n",
    "            \n",
    "        dist,az,baz = gps2dist_azimuth(evla, evlo,stla, stlo)\n",
    "        gcarc = kilometers2degrees(dist/1000)\n",
    "        \n",
    "        # Taup: theoretical travel times \n",
    "        model = TauPyModel(model=\"iasp91\")\n",
    "        arrivals = model.get_travel_times(source_depth_in_km=evdp,distance_in_degree=gcarc,phase_list=['P','PKP','PKIKP'])\n",
    "        \n",
    "        if len(arrivals) > 0 and (5 < gcarc < 100 or 140 < gcarc <= 180):\n",
    "            \n",
    "            # Event time + phase arrival time\n",
    "            evtime = evtime+arrivals[0].time\n",
    "            \n",
    "            # ----------------------------\n",
    "            # Check if feather file exists\n",
    "            \n",
    "            output_FEATHER_FILES_ORIENTATION = ORIENTATION_OUTPUT+'FEATHER_FILES/ORIENTATION/'+network+'.'+station+'/'\n",
    "            \n",
    "            file_feather_name = output_FEATHER_FILES_ORIENTATION+network+'.'+station+'.'+evname+'.orientation.feather'\n",
    "    \n",
    "            station_pwd = glob.glob(wave_dir+year+'/'+network+'/'+station+'/*')\n",
    "    \n",
    "            if os.path.isfile(file_feather_name):\n",
    "                pass\n",
    "        \n",
    "            else:\n",
    "                # -------------------------------\n",
    "                # Check if components file exists\n",
    "                        \n",
    "                if (len([i for i in station_pwd if 'HHE.D' in i or 'HH2.D' in i]) > 0 and\n",
    "                    len([i for i in station_pwd if 'HHN.D' in i or 'HH1.D' in i]) > 0 and\n",
    "                    len([i for i in station_pwd if 'HHZ.D' in i]) > 0):\n",
    "    \n",
    "                    if (len(glob.glob([i for i in station_pwd if 'HHE.D' in i or 'HH2.D' in i][0]+'/*'+year+'.'+julian_day)) > 0 and\n",
    "                        len(glob.glob([i for i in station_pwd if 'HHN.D' in i or 'HH1.D' in i][0]+'/*'+year+'.'+julian_day)) > 0 and\n",
    "                        len(glob.glob([i for i in station_pwd if 'HHZ.D' in i][0]+'/*'+year+'.'+julian_day)) > 0):\n",
    "                        \n",
    "                        file_HHE = glob.glob([i for i in station_pwd if 'HHE.D' in i or 'HH2.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "                        file_HHN = glob.glob([i for i in station_pwd if 'HHN.D' in i or 'HH1.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "                        file_HHZ = glob.glob([i for i in station_pwd if 'HHZ.D' in i][0]+'/*'+year+'.'+julian_day)[0]\n",
    "            \n",
    "                        # --------\n",
    "                        # Data HHE\n",
    "                                \n",
    "                        tr2_data_file = op.read(file_HHE)\n",
    "                        tr2_data_file.trim(evtime-TIME_WINDOW,evtime+TIME_WINDOW)\n",
    "                        tr2_data_file.taper(type='hann',max_percentage=0.1)\n",
    "                        tr2_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                    \n",
    "                        # --------\n",
    "                        # Data HHN\n",
    "                    \n",
    "                        tr1_data_file = op.read(file_HHN)\n",
    "                        tr1_data_file.trim(evtime-TIME_WINDOW,evtime+TIME_WINDOW)\n",
    "                        tr1_data_file.taper(type='hann',max_percentage=0.1)\n",
    "                        tr1_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "                            \n",
    "                        # --------\n",
    "                        # Data HHZ\n",
    "                                \n",
    "                        trZ_data_file = op.read(file_HHZ)\n",
    "                        trZ_data_file.trim(evtime-TIME_WINDOW,evtime+TIME_WINDOW)\n",
    "                        trZ_data_file.taper(type='hann',max_percentage=0.1)\n",
    "                        trZ_data_file.filter('bandpass',freqmin=PERIOD_BANDS[0],freqmax=PERIOD_BANDS[1],zerophase=True, corners=4)\n",
    "    \n",
    "                        if len(tr2_data_file) > 0 and len(tr1_data_file) > 0 and len(trZ_data_file) > 0:\n",
    "                                \n",
    "                            if (tr2_data_file[0].stats.npts == tr1_data_file[0].stats.npts == trZ_data_file[0].stats.npts) and (trZ_data_file[0].stats.npts > TIME_WINDOW * 100):\n",
    "                                \n",
    "                                tr2_data_filtered = tr2_data_file[0].data[1000:-1000]\n",
    "            \n",
    "                                tr1_data_filtered = tr1_data_file[0].data[1000:-1000]\n",
    "                                    \n",
    "                                trZ_data_filtered = trZ_data_file[0].data[1000:-1000]\n",
    "                                trZ_time = trZ_data_file[0].times()[1000:-1000]-TIME_WINDOW\n",
    "\n",
    "                                # -------------------------------------------\n",
    "                                # Function estimates the Akaike Information directly from data \n",
    "                                # The Summed Log Likelihood section implies that a natural \n",
    "                                # changepoint estimate is the sample index that minimizes \n",
    "                                # the AIC in equation\n",
    "                                \n",
    "                                aic_curve = aic_simple(trZ_data_filtered)\n",
    "                                \n",
    "                                k_min_index = np.argmin(aic_curve)\n",
    "                            \n",
    "                                time_P_arr = trZ_time[k_min_index]\n",
    "                                                        \n",
    "                                # Time error:\n",
    "                                time_ins = round(time_P_arr,1)\n",
    "                            \n",
    "                                if time_ins > 0:\n",
    "                                    signal_window_start = time_ins\n",
    "                                    signal_window_final = time_ins+TIME_FINAL_P\n",
    "                                    noise_window_start = time_ins\n",
    "                                    noise_window_final = time_ins-TIME_FINAL_P\n",
    "                                else:\n",
    "                                    signal_window_start = time_ins\n",
    "                                    signal_window_final = TIME_FINAL_P+time_ins\n",
    "                                    noise_window_start = time_ins\n",
    "                                    noise_window_final = -(abs(time_ins)+TIME_FINAL_P) \n",
    "                                # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                                # Signal and noise windows\n",
    "                                        \n",
    "                                signal_window = (trZ_time >= signal_window_start) & (trZ_time <= signal_window_final)\n",
    "                                noise_window = (trZ_time >= noise_window_final) & (trZ_time <= noise_window_start)\n",
    "                                \n",
    "                                noise = trZ_data_filtered[noise_window]\n",
    "                                trZ_noise_time = trZ_time[noise_window]\n",
    "            \n",
    "                                tr2 = tr2_data_filtered[signal_window]\n",
    "                                tr1 = tr1_data_filtered[signal_window]\n",
    "                                trZ = trZ_data_filtered[signal_window]\n",
    "                                trZ_signal_time = trZ_time[signal_window]\n",
    "                                    \n",
    "                                # -------------------------------------------------------------------------------------------------------------------------------\n",
    "                                # Calculating the optimal orientation\n",
    "                                                    \n",
    "                                results = Braunmiller_Pornsopin_algorithm(tr1,tr2,trZ,noise,baz,time_ins,CCVR_MIN=0.45,SNR_MIN=10,TRR_MIN=0.45,RVR_MIN=-1)\n",
    "\n",
    "                                # ----------------------------------------------------------------------------------------------------                               \n",
    "                                # Creating a Pandas DataFrame:\n",
    "                                column_info = [network,station,stla,stlo,evname,evla,evlo,evtime,evmag,evtype,evdp,dist,gcarc,baz,tr1_data_filtered,tr2_data_filtered,trZ_data_filtered,trZ_time,results['SS_best'],results['signal_strength'],results['SZR_best'],results['similarity_ZR'],results['ERTR_best'],results['energy_ratio_TR'],results['ERRZ_best'],results['energy_ratio_RZ'],results['SNR'],results['phi'],results['theta'],aic_curve,time_ins,results['quality']]\n",
    "                                columns_header = ['network','station','stla','stlo','evname','evla','evlo','evtime','evmag','evtype','evdp','distance','gcarc','baz','tr1_data','tr2_data','trZ_data','trZ_time','SS_best','signal_strength','SZR_best','similarity_vertical_radial','ERTR_best','energy_transverse_radial','ERRZ_best','energy_radial_vertical','SNR','phi','theta','aic_curve','clock_error','quality']\n",
    "                                orient_p_wave_df = pd.DataFrame(column_info, index=columns_header).T\n",
    "                                orient_p_wave_df['evtime'] = pd.to_datetime(orient_p_wave_df['evtime'].apply(lambda x: x.isoformat() if isinstance(x, UTCDateTime) else x))\n",
    "\n",
    "                                # ----------------------------------------------------------------------------------------------------\n",
    "                                # Convert from pandas to Arrow and saving in feather formart file\n",
    "                                os.makedirs(output_FEATHER_FILES_ORIENTATION,exist_ok=True)\n",
    "                                feather.write_feather(orient_p_wave_df, file_feather_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28368e53-7a2d-4acd-a368-aef64c5149ed",
   "metadata": {},
   "source": [
    "# Creating input list for different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c632f4-5e97-4fcd-b2e8-4cf0a7c39893",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "for xml_f in STATIONS_xml:\n",
    "    for wa_dir in WAVEFORM_DIR:\n",
    "        input_list.append([xml_f,wa_dir])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94993b08-0e9d-4564-9ad1-56f5543e3e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/NB.NBCL.ds.xml',\n",
       "  '/medata01/SEISCOMP_DATA/'],\n",
       " ['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/NB.NBCL.ds.xml',\n",
       "  '/medata02/SEISCOMP_DATA/'],\n",
       " ['/home/sysop/dados_posdoc/PROJETO_RSBR_15_YEARS/XML/NB.NBCL.ds.xml',\n",
       "  '/medata03/SEISCOMP_DATA/']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7aaff42-f461-40c1-90ff-78c6b83e6f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NBCL orientation: 100%|██████████████████████████████████████████████████████████| 2158/2158 [06:12<00:00,  5.79it/s]\n",
      "NBCL orientation: 100%|██████████████████████████████████████████████████████████| 2158/2158 [06:28<00:00,  5.55it/s]\n",
      "NBCL orientation: 100%|██████████████████████████████████████████████████████████| 2158/2158 [17:22<00:00,  2.07it/s]\n",
      "3it [17:22, 347.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- 17.37 execution time (min) ---\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with Pool(processes=num_processes) as p:\n",
    "    max_ = len(STATIONS_xml)\n",
    "    with tqdm(total=max_) as pbar:\n",
    "        for result in p.imap_unordered(calculate_orientation,input_list):\n",
    "            pbar.update()\n",
    "\n",
    "print('\\n')\n",
    "print(\"--- %.2f execution time (min) ---\" % ((time.time() - start_time)/60))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a13f6-a6e7-45bb-99a6-904caa2df3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
